#### 텐서플로우를 이용한 SVM으로 BMI(체질량)을 구하고 비만도를 판정하는 프로그램
### 키와 몸무게를 입력하면 '저체중: thin', '정상: normal', ; '비만:fat' 가 출력됨

import pandas as pd
import numpy as np
import tensorflow as tf

########## -----------------------------------------------------------------------
########## 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기 ---  2000만건 자료임
csv = pd.read_csv("c:/py_data/bmi.csv")
print(csv.head())
print(csv.info())

# 데이터 정규화 ---  키의 최대값은 200, 몸무게의 최대값은 100으로 지정
csv["height"] = csv["height"] / 200  
csv["weight"] = csv["weight"] / 100


######참고-----------------------------------------------------------------------------
csv["tmp_height"]=np.round(csv["height"],1)
print(csv.head())
tmp=pd.crosstab(csv['label'],csv['tmp_height'])
tmp



######## --------------------------------------------------------
######## thin=(1,0,0) / normal=(0,1,0) / fat=(0,0,1)   thin, normal, fat에 값부여
bclass = {"thin": [1,0,0], "normal": [0,1,0], "fat": [0,0,1]}
csv["label_pat"] = csv["label"].apply(lambda x : np.array(bclass[x]))  # apply 함수식 실행내장함수 : http://sjs0270.tistory.com/144
print(csv.head())

# lambda는 여러개의 변수, 함수를 한줄에 사용할수 있게함.  def add(x,y): return x+y   를 lambda x+y
# https://wikidocs.net/64 




############### -------------------------------------------------------------------
############   테스트를 위한 데이터 분류 --- 
test_csv = csv[15000:20000]    #전체데이터중   25% 5000개
test_pat = test_csv[["weight","height"]]
test_ans = list(test_csv["label_pat"])
#print(test_pat)
#print(test_ans)



############# ------------------------------------------------------------------------
############ 데이터 플로우 그래프 구출하기 --- 텐서플로우 공식 튜토리얼의 '소프트맥스 회귀'방법
###### Softmax(소프트맥스)는 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 됨
##### 분류하고 싶은 클래수의 수 만큼 출력으로 구성한다.
##### 가장장 큰 출력 값을 부여받은 클래스가 확률이 가장 높은 것으로 이용된다.
# 플레이스홀더 선언하기

x  = tf.placeholder(tf.float32, [None, 2]) # 키와 몸무게 데이터 넣기, 키 1열, 몸무게 2열
y_ = tf.placeholder(tf.float32, [None, 3]) # 정답 레이블 넣기,  thin(1,0,0), normal(0,1,0), fat(0,0,1)


# 변수 선언하기 --- 입력X가 있을때의 y계산식,   ax+b 함수 변수선언
W = tf.Variable(tf.zeros([2, 3])); # 가중치
b = tf.Variable(tf.zeros([3])); # 바이어스   thin이거나 normal이거나 fat이거나 3열중 한곳에 들어감.


# 소프트맥스 회귀 정의하기 ---  소프트맥스식 x는 입력, W는 가중치, b는 바이어스
y = tf.nn.softmax(tf.matmul(x, W) + b)


# 모델 훈련하기 --- 데이터를 학습하는 모델에서 오차함수(교차엔트로피:cross entropy)사용
# 교차엔트로피: 2개의 확률 분포 사이에 정의되는 척도, 교차엔트로피 값이 작을수록 정확한 값을 냄.

cross_entropy = -tf.reduce_sum(y_ * tf.log(y))
optimizer = tf.train.GradientDescentOptimizer(0.01)   #0.01 학습률,경사하강법을 사용하여 0.01단위로 곱하면서 재계산함.
train = optimizer.minimize(cross_entropy)


####  정답률 구하기
predict = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))

##### 세션 시작하기
sess = tf.Session()
sess.run(tf.global_variables_initializer()) # 변수 초기화하기


#### 학습시키기
for step in range(3500):
    i = (step * 100) % 14000
    rows = csv[1 + i : 1 + i + 100]    #1~101, 2~103, 3~104
    x_pat = rows[["weight","height"]]
    y_ans = list(rows["label_pat"])
    fd = {x: x_pat, y_: y_ans}
    sess.run(train, feed_dict=fd)
    if step % 500 == 0:    # step를 500으로 나누기했을때 0이라면 
        cre = sess.run(cross_entropy, feed_dict=fd)
        acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})
        print("step=", step, "cre=", cre, "acc=", acc)


# 최종적인 정답률 구하기
acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})
print("정답률 =", acc)