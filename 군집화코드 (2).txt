#-----150개의 iris 꽃 리스트,  caseno(번호), SpealLengh(꽃받침길이) SepalWidth(꽃받침너비)
#------ PetalLength(꽃잎길이) PetalWidth(꽃잎너비), Speices(꽃의종류)

import pandas as pd
tmp=pd.read_csv("c:/py_data/iris.csv")
tmp.head()
pd.crosstab(tmp['labels'],tmp['Species'])


####-- 산포도행렬
import matplotlib.pyplot as plt
from pandas.tools.plotting import scatter_matrix
scatter_matrix(tmp)
plt.show()


#-------- 실행데이터 새로 구성
a=tmp['SepalLength'] ; b=tmp['SepalWidth']
feature=pd.concat([a,b],axis=1)
feature.head()



#----- KMeans 모듈 사용할 라이브러리 import
from sklearn.cluster import KMeans  #KMeans 모듈


#----- 3개의 클러스터로 군집화(라벨 0,1,2),  model.fit(학습데이터)
model = KMeans(n_clusters=3,algorithm='auto')
model.fit(feature)  #중심점 추출함  이 학습모델을 갖고 데이터를 수행함(model.predic)
predict = pd.DataFrame(model.predict(feature))
predict.columns=['predict']
r=pd.concat([feature,predict],axis=1)
r.head()


# ----- 시각화
import matplotlib.pyplot  as plt   #차트
import seaborn as sns   # 차트
plt.scatter(r['SepalLength'],r['SepalWidth'],c=r['predict'], alpha=0.5)


#-- 각 군집의 중심점에 빨간점으로 표시하자
centers = pd.DataFrame(model.cluster_centers_,columns=['SepalLength','SepalWidth'])
center_x = centers['SepalLength']
center_y = centers['SepalWidth']
plt.scatter(center_x,center_y,s=50,marker='D',c='r')
plt.show()


#-----  데이터스케일링 (필드값(각컬럼) 예: StandardScaling(숫자값의 범위를 0~1상이의 같은 크기로 맞춤)
#- 여러 단계를 거쳐서 데이타가 정재되고 학습되는 것을 파이프라인이라고 하고, sklearn.pipeline을 이용하여 손쉽게 구현이 가능하다
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans


##---먼저 StandardScaler 객체 scaler를 만든 후, KMeans 모델 객체를 model로 선언한다. 다음에 make_pipeline 메서드를 이용하여 scaler kmeans 모델을 순차로 실행하도록 파이프라인을 만든다.
scaler = StandardScaler()
model = KMeans(n_clusters=3)
pipeline = make_pipeline(scaler,model)

## -- pipeline.fit과 .predict 메서드를 이용하여 모델을 학습 시키고 예측을 수행한다.
##--iris 예제의 경우 스케일링을 적용하더라도 크게 모델의 정확도가 향상된것을 확인할 수 없음
##  이유는 Sepal length의 범위가 4~8, Sepal width의 범위가 2~5로 각 범위의 편차가 크지 않기 때문에 스케일링이 효과가 없다. 
pipeline.fit(feature)
predict = pd.DataFrame(pipeline.predict(feature))
predict.head()




# 중심점에서의 각 떨어짐의 정도를 응집도라한다.
# 응집도가 (     )수록 군집화는 잘되어 있다. 군집화는 model.inertia_ 함수로 알아볼수 있다.
# 4개의 클러스터로 군집화(라벨 0,1,2),  model.fit(학습데이터)
model = KMeans(n_clusters=4,algorithm='auto')
model.fit(feature)  #중심점 추출함  이 학습모델을 갖고 데이터를 수행함(model.predic)
model.inertia_


########## 10개의 자료를 주고 응집도 계산
row=10
cnt=range(1,row)
k=[]
for i in cnt:
    model=KMeans(n_clusters=i)
    model.fit(feature)
    #k[i-1]=model.inertia_
    k.append(model.inertia_)
    print("i={0}, k={1}".format(i,k))





# 응집도 차트로 보기Plot ks vs inertias
plt.plot(k, '-o')
plt.xlabel('number of clusters, k')
plt.ylabel('inertia')
plt.xticks(ks)
plt.show()


#########검증
ct = pd.crosstab(tmp['labels'],r['predict'])
print (ct)

